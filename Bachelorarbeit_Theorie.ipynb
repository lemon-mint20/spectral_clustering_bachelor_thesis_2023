{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Spectral Clustering – eine empirische Untersuchung**\n",
    "\n",
    "# Implementierung für Theorieteil\n",
    "\n",
    "\n",
    "## Freie wissenschaftliche Arbeit zur Erlangung des akademischen Grades Bachelor of Science\"\n",
    "\n",
    "Studiengang: Wirtschaftsinformatik\n",
    "\n",
    "**an der Wirtschaftswissenschaftlichen Fakultät der Universität Augsburg**\n",
    "\n",
    "Lehrstuhl für Statistik\n",
    "\n",
    "Eingereicht bei: Prof. Dr. Yarema Okhrin\n",
    "\n",
    "Betreuerin:      Christine Distler (M. Sc.)\n",
    "\n",
    "Vorgelegt von:\n",
    "\n",
    "Adresse:\n",
    ">\n",
    ">\n",
    ">\n",
    "\n",
    "\n",
    "\n",
    "Augsburg, im März 2023\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating synthetic Dataset"
   ],
   "metadata": {
    "id": "NP_NYQkRvMTz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zS8yI6Ib3B-"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = datasets.make_blobs(n_samples=10, centers=2, cluster_std=2, random_state=1)\n",
    "# X, y = datasets.make_blobs(n_samples=21, centers=3, cluster_std=0.5, random_state=2)\n",
    "# X, y = datasets.make_blobs(n_samples=40, centers=4, cluster_std=0.4, random_state=2)\n",
    "\n",
    "plt.scatter(x=X[:, 0], y=X[:,1], s=30)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "l9Kl3Ko0cGdI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X, y"
   ],
   "metadata": {
    "id": "Ylnaa3G18Zus"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dieser Code stammt ursprünglich aus der Spectral Clustering Implementation von Dr. Yikun Zhang auf seinem [github Repository](https://github.com/zhangyk8/Spectral-Clustering/blob/master/spectral_clustering.py), wurde aber von mir modifiziert, um Graphen und Matrizen zurückzugeben.\n",
    " Zugriff: 05.12.2023"
   ],
   "metadata": {
    "id": "nTJsUfK2dMbq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import KMeans"
   ],
   "metadata": {
    "id": "hZq-nGnoJiJm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Based on \"A Tutorial on Spectral Clustering\" written by Ulrike von Luxburg\n",
    "def Spectral_Clustering(X, K=8, adj=True, metric='euclidean', sim_graph='fully_connect', sigma=1.0, knn=10, epsi=0.5,\n",
    "                        normalized=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X : [n_samples, n_samples] numpy array if adj=True, or, a [n_samples_a, n_features] array otherwise;\n",
    "\n",
    "        K: int, The number of clusters;\n",
    "\n",
    "        adj: boolean, Indicating whether the adjacency matrix is pre-computed. Default: True;\n",
    "\n",
    "        metric: string, A parameter passing to \"scipy.spatial.distance.pdist()\" function for computing the adjacency\n",
    "        matrix (deprecated if adj=True). Default: 'euclidean';\n",
    "\n",
    "        sim_graph: string, Specifying the type of similarity graphs. Choices are ['fully_connect', 'eps_neighbor',\n",
    "        'knn', 'mutual_knn']. Default: 'fully_connect';\n",
    "\n",
    "        sigma: float, The variance for the Gaussian (aka RBF) kernel (Used when sim_graph='fully_connect'). Default: 1;\n",
    "\n",
    "        knn: int, The number of neighbors used to construct k-Nearest Neighbor graphs (Used when sim_graph='knn'\n",
    "        or 'mutual_knn'). Default: 10;\n",
    "\n",
    "        epsi: float, A parameter controlling the connections between points (Used when sim_graph='eps_neighbor').\n",
    "        Default: 0.5;\n",
    "\n",
    "        normalized: int, 1: Random Walk normalized version; 2: Graph cut normalized version; other integer values:\n",
    "        Unnormalized version. Default: 1.\n",
    "\n",
    "    Output:\n",
    "        sklearn.cluster class, Attributes:\n",
    "            cluster_centers_ : array, [n_clusters, n_features], Coordinates of cluster centers in K-means;\n",
    "            labels_ : Labels of each point;\n",
    "            inertia_ : float, Sum of squared distances of samples to their closest cluster center in K-means;\n",
    "            n_iter_ : int, Number of iterations run in K-means.\n",
    "    \"\"\"\n",
    "    # Compute the adjacency matrix\n",
    "    if not adj:\n",
    "        Adj_mat = squareform(pdist(X, metric=metric))\n",
    "    else:\n",
    "        Adj_mat = X\n",
    "    # Compute the weighted adjacency matrix based on the type of similarity graphs\n",
    "    if sim_graph == 'fully_connect':\n",
    "        W = np.exp(-np.square(Adj_mat) / (2 * sigma)**2)\n",
    "    elif sim_graph == 'eps_neighbor':\n",
    "        W = (Adj_mat <= epsi).astype('float64')\n",
    "    elif sim_graph == 'knn':\n",
    "        W = np.zeros(Adj_mat.shape)\n",
    "        # Sort the adjacency matrx by rows and record the indices\n",
    "        Adj_sort = np.argsort(Adj_mat, axis=1)\n",
    "        # Set the weight (i,j) to 1 when either i or j is within the k-nearest neighbors of each other\n",
    "        for i in range(Adj_sort.shape[0]):\n",
    "            W[i, Adj_sort[i, :][:(knn + 1)]] = 1\n",
    "    elif sim_graph == 'mutual_knn':\n",
    "        W1 = np.zeros(Adj_mat.shape)\n",
    "        # Sort the adjacency matrx by rows and record the indices\n",
    "        Adj_sort = np.argsort(Adj_mat, axis=1)\n",
    "        # Set the weight W1[i,j] to 0.5 when either i or j is within the k-nearest neighbors of each other (Flag)\n",
    "        # Set the weight W1[i,j] to 1 when both i and j are within the k-nearest neighbors of each other\n",
    "        for i in range(Adj_mat.shape[0]):\n",
    "            for j in Adj_sort[i, :][:(knn + 1)]:\n",
    "                if i == j:\n",
    "                    W1[i, i] = 1\n",
    "                elif W1[i, j] == 0 and W1[j, i] == 0:\n",
    "                    W1[i, j] = 0.5\n",
    "                else:\n",
    "                    W1[i, j] = W1[j, i] = 1\n",
    "        W = np.copy((W1 > 0.5).astype('float64'))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"The 'sim_graph' argument should be one of the strings, 'fully_connect', 'eps_neighbor', 'knn', or 'mutual_knn'!\")\n",
    "\n",
    "    # Compute the degree matrix and the unnormalized graph Laplacian\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "    L = D - W\n",
    "\n",
    "    # Compute the matrix with the first K eigenvectors as columns based on the normalized type of L\n",
    "    if normalized == 1:  ## Random Walk normalized version\n",
    "        # Compute the inverse of the diagonal matrix\n",
    "        D_inv = np.diag(1 / np.diag(D))\n",
    "        # Compute the eigenpairs of L_{rw}\n",
    "        Lambdas, V = np.linalg.eig(np.dot(D_inv, L))\n",
    "        # Sort the eigenvalues by their L2 norms and record the indices\n",
    "        ind = np.argsort(np.linalg.norm(np.reshape(Lambdas, (1, len(Lambdas))), axis=0))\n",
    "        V_K = np.real(V[:, ind[:K]])\n",
    "    elif normalized == 2:  ## Graph cut normalized version\n",
    "        # Compute the square root of the inverse of the diagonal matrix\n",
    "        D_inv_sqrt = np.diag(1 / np.sqrt(np.diag(D)))\n",
    "        # Compute the eigenpairs of L_{sym}\n",
    "        Lambdas, V = np.linalg.eig(np.matmul(np.matmul(D_inv_sqrt, L), D_inv_sqrt))\n",
    "        # Sort the eigenvalues by their L2 norms and record the indices\n",
    "        ind = np.argsort(np.linalg.norm(np.reshape(Lambdas, (1, len(Lambdas))), axis=0))\n",
    "        V_K = np.real(V[:, ind[:K]])\n",
    "        if any(V_K.sum(axis=1) == 0):\n",
    "            raise ValueError(\n",
    "                \"Can't normalize the matrix with the first K eigenvectors as columns! Perhaps the number of clusters K or the number of neighbors in k-NN is too small.\")\n",
    "        # Normalize the row sums to have norm 1\n",
    "        V_K = V_K / np.reshape(np.linalg.norm(V_K, axis=1), (V_K.shape[0], 1))\n",
    "    else:  ## Unnormalized version\n",
    "        # Compute the eigenpairs of L\n",
    "        Lambdas, V = np.linalg.eig(L)\n",
    "        # Sort the eigenvalues by their L2 norms and record the indices\n",
    "        ind = np.argsort(np.linalg.norm(np.reshape(Lambdas, (1, len(Lambdas))), axis=0))\n",
    "        V_K = np.real(V[:, ind[:K]])\n",
    "\n",
    "    # Conduct K-Means on the matrix with the first K eigenvectors as columns\n",
    "    kmeans = KMeans(n_clusters=K, init='k-means++', random_state=0).fit(V_K)\n",
    "    return kmeans, W, Adj_mat, Lambdas, V, V_K"
   ],
   "metadata": {
    "id": "HzIFmAEJcxhi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "show weighted adjancency matrices"
   ],
   "metadata": {
    "id": "nIbwRZUretMK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Lamb = None\n",
    "experiment_parameters = {\n",
    "    'K': 2,\n",
    "    'sigma': 1,\n",
    "\n",
    "    'epsilon': 3.5,\n",
    "\n",
    "    'knn': 3, \n",
    "}\n",
    "\"\"\"\n",
    "experiment_parameters = {\n",
    "    'K': 3,\n",
    "    'sigma': 1,\n",
    "\n",
    "    'epsilon': 3.5,\n",
    "\n",
    "    'knn': 3, \n",
    "}\"\"\"\n",
    "\n",
    "type_W = None\n",
    "graphs = []\n",
    "sim_graphs = ['fully_connect', 'eps_neighbor', 'knn', 'mutual_knn']\n",
    "\n",
    "for graph_type in sim_graphs:\n",
    "  kmeans_, W_, Adj_, Lambdas_, V_, V_K_ = Spectral_Clustering(X = X, K=experiment_parameters['K'], adj=False, sim_graph=graph_type, \n",
    "                                       knn=experiment_parameters['knn'], epsi=experiment_parameters['epsilon'])\n",
    "  np.fill_diagonal(W_, 0)\n",
    "  graphs.append(W_)\n",
    "  \n",
    "  if(graph_type == 'fully_connect'):\n",
    "    print('not weigted Adjancency Martix (euclidean distance)')\n",
    "    print(Adj_.round(2))\n",
    "    print('Lambdas')\n",
    "    print(Lambdas_.round(3))\n",
    "    Lamb = Lambdas_\n",
    "    print('V')\n",
    "    print(V_.round(5))\n",
    "    print('V_K')\n",
    "    print(V_K_.round(2))\n",
    "    print(kmeans_.labels_)\n",
    "  \n",
    "\n",
    "  print(graph_type)\n",
    "  print(W_.round(3))"
   ],
   "metadata": {
    "id": "U1niiB8WeA0t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# draw graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ],
   "metadata": {
    "id": "PxCbKagnnTTl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x_labels = {\n",
    "    sim_graphs[0]: f\"with Gaussian similarity function, sigma={experiment_parameters['sigma']}\",\n",
    "    sim_graphs[1]: f\"epsilon={experiment_parameters['epsilon']}\",\n",
    "    sim_graphs[2]: f\"k={experiment_parameters['knn']}\",\n",
    "    sim_graphs[3]: f\"k={experiment_parameters['knn']}\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(graphs)):\n",
    "  G = nx.from_numpy_array(graphs[i])\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  nx.draw_networkx(G, pos=nx.circular_layout(G), font_color='white')\n",
    "  plt.title(sim_graphs[i])\n",
    "  plt.xlabel(x_labels[sim_graphs[i]])"
   ],
   "metadata": {
    "id": "yYV9jFFQnIpO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "G = nx.from_numpy_array(graphs[0])\n",
    "nx.draw_networkx(G, pos=nx.circular_layout(G), font_color='white', \n",
    "                 node_size=1500, font_size=16)\n",
    "plt.xlabel(x_labels[sim_graphs[0]])\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "i3x7Pa1CcJVq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/62935983/vary-thickness-of-edges-based-on-weight-in-networkx\n",
    "ACCESS: 2023-02-15 20:06\n",
    "\"\"\"\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "G = nx.from_numpy_array(graphs[0])\n",
    "widths = nx.get_edge_attributes(G, 'weight')\n",
    "nodelist = G.nodes()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "pos = nx.shell_layout(G)\n",
    "nx.draw_networkx_nodes(G,pos,\n",
    "                       nodelist=nodelist,\n",
    "                       node_size=1000,\n",
    "                       node_color='black',\n",
    "                       alpha=1)\n",
    "nx.draw_networkx_edges(G,pos,\n",
    "                       edge_color='black',\n",
    "                       alpha=1)\n",
    "nx.draw_networkx_labels(G, pos=pos,\n",
    "                        labels=dict(zip(nodelist,nodelist)),\n",
    "                        font_color='white')\n",
    "ED = G.edges(data=True)\n",
    "for u,v,w in ED:\n",
    "  w['weight'] = round(w['weight'],3)\n",
    "nx.draw_networkx_edge_labels(G,pos=pos, edge_labels=nx.get_edge_attributes(G, 'weight'))\n",
    "\n",
    "plt.box(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "dAnlteP0dKDO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Untersuchen der Gausschen Ähnlichkeitsfunktion"
   ],
   "metadata": {
    "collapsed": false,
    "id": "bFryYfNJJKkH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn import datasets"
   ],
   "metadata": {
    "id": "hvPQKc_pJKkI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X2, y2 = datasets.make_blobs(n_samples=15, centers=2,\n",
    "                           random_state=0)\n",
    "Adj_mat = squareform(pdist(X2, metric='euclidean'))\n",
    "def gaussian(mat, sigma):\n",
    "    return np.exp(-np.square(mat) / (2 * sigma)**2)\n",
    "\n"
   ],
   "metadata": {
    "id": "PmbF7JipJKkI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Adj_mat"
   ],
   "metadata": {
    "id": "hc-5qpo6JKkI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian(Adj_mat, 0.1)"
   ],
   "metadata": {
    "id": "BzgAMadgJKkJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaussian(Adj_mat, 1.2)"
   ],
   "metadata": {
    "id": "p5b1zhqPJKkJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the data from Adj_mat at x and gaussian(Adj_mat, 1.2) at y\n",
    "# in the same plot plot the data from Adj_mat at x and gaussian(Adj_mat, 0.1) at y\n",
    "# plot with legend\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(Adj_mat, gaussian(Adj_mat, 1.5))\n",
    "plt.scatter(Adj_mat, gaussian(Adj_mat, 0.8))\n",
    "plt.scatter(Adj_mat, gaussian(Adj_mat, 0.3))\n",
    "plt.xlabel('Adjacency Matrix')\n",
    "plt.ylabel('Gaussian Similarity Function')\n",
    "plt.legend(['sigma=1.2', 'sigma=0.6', 'sigma=0.1'])\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "RssGXd3EJKkK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Walk Laplacian $L_{rw}$\n"
   ],
   "metadata": {
    "id": "3BbPphKuPZOw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Adj_mat = squareform(pdist(X, metric='euclidean'))\n",
    "W = np.exp(-np.square(Adj_mat) / (2 * 0.5)**2)\n",
    "D = np.diag(np.sum(W, axis=1))\n",
    "L = D - W\n",
    "D_inv = np.diag(1 / np.diag(D))\n",
    "L_rw = np.dot(D_inv, L)\n",
    "print(L_rw.round(2))"
   ],
   "metadata": {
    "id": "RiCdyrEGRdeM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Lambdas, V = np.linalg.eig(np.dot(D_inv, L))\n",
    "print(V.shape)\n",
    "print(Lambdas)"
   ],
   "metadata": {
    "id": "o2OKUE-2fVjq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Eigengap Heuristic\n",
    "\n",
    "# np.argsort(np.diff(Lamb))[::-1][:5]\n",
    "print(np.argsort(np.diff(Lamb)))\n",
    "print(f'Eigenvalues: {Lamb}')\n",
    "def maxDiffIndex(array): \n",
    "  # Sortiere das Array\n",
    "  array = np.sort(array) \n",
    "  # Initialisiere eine Variable für den größtmöglichen Index \n",
    "  max_diff_index = 0\n",
    "  # Initialisiere eine Variable für die größtmögliche Differenz \n",
    "  max_diff = 0\n",
    "  \n",
    "  # Iteriere über das Array \n",
    "  for i in range(1, len(array)): \n",
    "    # Berechne die Differenz zwischen zwei aufeinander folgenden Elementen\n",
    "    diff = array[i] - array[i-1]\n",
    "    # Prüfe, ob die Differenz größer als die vorherige ist\n",
    "    if diff > max_diff:\n",
    "      # Wenn ja, speichere diesen Index und die Differenz in den Variablen\n",
    "      max_diff_index = i\n",
    "      max_diff = diff\n",
    "  \n",
    "  # Gib den größtmöglichen Index und die Differenz\n",
    "  return max_diff_index, max_diff\n",
    "print(maxDiffIndex(Lamb))"
   ],
   "metadata": {
    "id": "0hfVFuoRLoqe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter([i for i in range(len(Lamb))], np.sort(Lamb))"
   ],
   "metadata": {
    "id": "K2-Nkvqisr8o"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
